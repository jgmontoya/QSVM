# QSVM

Comparison of quantum-enhanced SVM vs classical SVM using the well-known Iris dataset.

## Repository for the project of the 2019 version of the Quantum Computing course given by prof. Rudy Raymond

### University of Tokyo

## The team

Name | Github | Email
-----|--------|-------
Corentin Pouget | [@Dwinlight](https://github.com/Dwinlight) | corentinpouget15@gmail.com
Javier G. Montoya S. | [@jgmontoya](https://github.com/jgmontoya) | jgmontoya@uc.cl
Lanke Fu | [@ThatFrankGuy](https://github.com/ThatFrankGuy) | lanke_fu@outlook.com
Pua Kai | [@Chokomancarr](https://github.com/Chokomancarr) | puakai2010@gmail.com
Yulu Pan | [@pandaman64](https://github.com/pandaman64) | pandaman64@gmail.com
Wei Xiao | [@bearsan](https://github.com/bearsan) | bearsanxw@gmail.com

## Topics

### Best Classical Parameter Combination - Javier?

### Multi-class Extension - Frank
One Against Rest

All Pairs

Error Correcting Code


### Feature Maps
First Order Expansion - Coco

Second Order Expansion - Kai

Pauli Expansion - Frank

Pauli Z Expansion - Xiao Wei




####Features maps explanation (by Coco): 
Just a little summarize about I understood in general about feature maps:
As we know feature maps have the same kind of utility than the Kernel. So it adds a new dimension to our dataset which could help us to create an efficient model
But the feature maps can also reduce the number of data that you have in the training data set. This is called dimension reduction. 
So the feature maps can remove some features (columns) in our training data set if this is relevant to do so. 

