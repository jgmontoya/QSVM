{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the dataset and preprocess it to feed it to the QSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_scale(training, testing, features, gaussian=True, minmax=False):\n",
    "    # Normalizes and/or scales both datasets based on the training dataset.\n",
    "    \n",
    "    sample_train = training.copy()\n",
    "    sample_test = testing.copy()\n",
    "    \n",
    "    if gaussian:\n",
    "        # Gaussian around 0 with unit variance normalization\n",
    "        for feature in features:\n",
    "            mean = sample_train[feature].mean()\n",
    "            std = sample_train[feature].std()\n",
    "            sample_train[feature] = (sample_train[feature] - mean)/std\n",
    "            sample_test[feature] = (sample_test[feature] - mean)/std\n",
    "    \n",
    "    if minmax:\n",
    "        # Scale features to the range (0,1)\n",
    "        for feature in features:\n",
    "            min_val = sample_train[feature].min()\n",
    "            max_val = sample_train[feature].max()\n",
    "            dif = (max_val - min_val)\n",
    "            sample_train[feature] = (sample_train[feature] - min_val)/dif\n",
    "            sample_test[feature] = (sample_test[feature] - min_val)/dif\n",
    "\n",
    "    return sample_train, sample_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LoadDataset(training_path, testing_path, features, label, gaussian=True, minmax=False):\n",
    "    '''Loads the data, normalizes it and returns it in the following format:\n",
    "    {class_0: points_dataframe_0, class_1:points_dataframe_1, ...}\n",
    "    Where points_dataframe_i corresponds to the points that belong to class_i as a pandas dataframe\n",
    "    '''\n",
    "    df_train = pd.read_csv(training_path, index_col=0)\n",
    "    df_test = pd.read_csv(testing_path, index_col=0)\n",
    "    \n",
    "    train, test = normalize_and_scale(df_train, df_test, features)\n",
    "    \n",
    "    train_dict, test_dict = {}, {}\n",
    "    for category in train[label].unique():\n",
    "        train_dict[category] = train[train['Species'] == category][features]\n",
    "        test_dict[category] = test[test['Species'] == category][features]\n",
    "    \n",
    "    return train_dict, test_dict\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "# features = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
    "# LoadDataset('../dataset/Iris_training.csv', '../dataset/Iris_testing.csv', features, label='Species')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
